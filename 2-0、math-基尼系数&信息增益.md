# 基尼系数与信息增益深度解析

## 一、基尼系数 (Gini Index)

### 1.1 定义

基尼系数是衡量数据集不纯度或不确定性的指标，用于分类问题中评估分裂点的质量。它表示从数据集中随机抽取两个样本，它们属于不同类别的概率。

### 1.2 公式


<img width="338" height="82" alt="image" src="https://github.com/user-attachments/assets/0c8afd88-b048-4676-8919-6d9427d801f9" />


其中：

- D：当前数据集
- K：类别总数
- pk：第k类样本在D中的比例

### 1.3 值域范围

- **最小值**：0（完全纯净，所有样本属于同一类别）
- **最大值**：1−K1（当所有类别等比例分布时）

### 1.4 使用场景

- 分类问题中评估分裂点质量
- 决策树算法（如CART）的主要分裂准则


### 1.5 分裂准则

选择使分裂后子节点基尼系数加权和最小的分裂点：

<img width="330" height="97" alt="image" src="https://github.com/user-attachments/assets/4d5fdb40-6f99-4c42-abd1-b20a46f0353f" />


### 1.6 优缺点

**优点**：

- 计算简单高效
- 不需要对数运算
- 对类别不平衡不敏感

**缺点**：

- 倾向于选择类别数量多的分裂
- 对类别分布变化不敏感

## 二、信息增益 (Information Gain)

### 2.1 定义

信息增益基于信息熵，表示分裂前后信息熵的减少量。它衡量通过特征分裂后，数据集不确定性减少的程度。

### 2.2 相关概念

<img width="865" height="256" alt="image" src="https://github.com/user-attachments/assets/f16c6514-7602-4732-b2c3-bad88ad8e28a" />

其中：

- A：分裂特征
- V：特征A的取值数
- Dv：特征A取值为v的子集

### 2.3 值域范围

- **最小值**：0（分裂后不确定性未减少）
- **最大值**：Entropy(D)（分裂后完全纯净）

### 2.4 使用场景

- 分类问题中评估特征重要性
- 决策树算法（如ID3、C4.5）的主要分裂准则

### 2.5 分裂准则

选择信息增益最大的分裂点

### 2.6 优缺点

**优点**：

- 理论基础强（信息论）
- 倾向于选择类别数量少的分裂
- 对类别分布变化敏感

**缺点**：

- 计算复杂度高（需要对数运算）
- 倾向于选择取值多的特征（需要信息增益率校正）
